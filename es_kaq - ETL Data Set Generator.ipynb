{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "from pyspark.sql.functions import col, lower, regexp_replace, split, trim\n",
    "from decimal import Decimal\n",
    "from termcolor import colored\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    print(\"Then: \", text)\n",
    "    text = lower(text)\n",
    "    text = trim(text)\n",
    "    text = regexp_replace(text, \"’\", \"'\")\n",
    "    text = regexp_replace(text, '\"', \"\")\n",
    "    text = regexp_replace(text, \"[\\s]+[\\n]+\", \"\")\n",
    "    text = regexp_replace(text, \"\\t\", \"\")\n",
    "    text = regexp_replace(text, \"\\s\", \" \")\n",
    "    print(\"Now: \", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos de aplicación de Spark\n",
    "appName = \"es_kaq_dataset\"\n",
    "master = \"spark://mynorxico:7077\"\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "    .appName(appName)\\\n",
    "    .master(master)\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder de los datasets\n",
    "file_path = \"../Desktop/raw_sentences/\"\n",
    "a = '\"\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Español-Kaqchikel de Nuevo Testamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(StructType(List(StructField(_id,StringType,true),StructField(_type,StringType,true),StructField(content,StringType,true))),\n",
       " StructType(List(StructField(_id,StringType,true),StructField(_type,StringType,true),StructField(content,StringType,true))))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cak_file_name = \"Cakchiquel-NT.xml\"\n",
    "es_file_name = \"Spanish.xml\"\n",
    "\n",
    "# Creación de dataframes\n",
    "df_es = spark.read.format('xml')\\\n",
    "    .options(rowTag=\"seg\")\\\n",
    "    .load(file_path+es_file_name)\n",
    "df_cak = spark.read.format('xml')\\\n",
    "    .options(rowTag=\"seg\")\\\n",
    "    .load(file_path+cak_file_name)\n",
    "(df_es.schema, df_cak.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+--------------------+\n",
      "|      _id|_type|             content|\n",
      "+---------+-----+--------------------+\n",
      "|b.GEN.1.1|verse|\n",
      "\t\t\t\t\t\tEn el prin...|\n",
      "|b.GEN.1.2|verse|\n",
      "\t\t\t\t\t\tY la tierr...|\n",
      "+---------+-----+--------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+---------+-----+--------------------+\n",
      "|      _id|_type|             content|\n",
      "+---------+-----+--------------------+\n",
      "|b.MAT.1.1|verse|\n",
      "\t\t\t\t\t\tRe wuj ri ...|\n",
      "|b.MAT.1.2|verse|\n",
      "\t\t\t\t\t\tRi Abraham...|\n",
      "+---------+-----+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Primeros dos versos de cada dataframe\n",
    "df_es.show(2)\n",
    "df_cak.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner join para hacer match de dataframe de español y dataframe de kaqchikel\n",
    "cak = df_cak.alias('cak')\n",
    "es = df_es.alias('es')\n",
    "df_new_testament = es.join(cak, es._id==cak._id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Kaqchikel verses:  7852\n",
      "#Spanish verses:  31100\n",
      "#cak_es new testament verses:  7851\n"
     ]
    }
   ],
   "source": [
    "print(\"#Kaqchikel verses: \", cak.count())\n",
    "print(\"#Spanish verses: \", es.count())\n",
    "\n",
    "print(\"#cak_es new testament verses: \", df_new_testament.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Español-Kaqchikel de Historia y Leyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_filename = \"es_kaq_dataset.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_history_law = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"delimiter\", \"|\")\\\n",
    "    .load(f\"{file_path}{history_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3098"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_history_law.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenando Ambos Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Then:  Column<'es'>\n",
      "Now:  Column<'regexp_replace(regexp_replace(regexp_replace(regexp_replace(regexp_replace(trim(lower(es)), ’, ', 1), \", , 1), [\\s]+[\n",
      "]+, , 1), \t, , 1), \\s,  , 1)'>\n",
      "Then:  Column<'cak'>\n",
      "Now:  Column<'regexp_replace(regexp_replace(regexp_replace(regexp_replace(regexp_replace(trim(lower(cak)), ’, ', 1), \", , 1), [\\s]+[\n",
      "]+, , 1), \t, , 1), \\s,  , 1)'>\n",
      "+--------------------+--------------------+\n",
      "|                  es|                 cak|\n",
      "+--------------------+--------------------+\n",
      "|            abogado.|solonel mak/to'onel.|\n",
      "|profesional del d...|ri etamanel rik'i...|\n",
      "|            abortar.|           tzaqonïk.|\n",
      "|provocar la muert...|rukamik jun ne'y ...|\n",
      "|        absolutorio.|majun rumak/kuyun...|\n",
      "| efecto de absolver.|rub'anik jun kuyu...|\n",
      "|           absolver.|          kuyuj mak.|\n",
      "|perdón o dar por ...|rukuyik rumak jun...|\n",
      "|         posiciones.|         ch'ob'onïk.|\n",
      "|cuando una de las...|toq jun chi ke ri...|\n",
      "|         abstención.|choj k'ojlem/q'i'...|\n",
      "|    falta de acción.|majun achike ta x...|\n",
      "|           accesión.|           k'iyirem.|\n",
      "|modo de adquirir ...|jun rub'eyal rich...|\n",
      "|acceso a la infor...|  ruk'ulik rutzijol.|\n",
      "|es el derecho de ...|jun ruch'ojib'al ...|\n",
      "|dicha información...|re to'ïk re' rich...|\n",
      "|             acción.|         ch'ojib'äl.|\n",
      "|derecho de presen...|ruch'ojib'al jun ...|\n",
      "|       acción penal.| ruk'utik ajch'a'oj.|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "10659\n",
      "Shuffled df count:  10659\n",
      "Quitando entrenamiento:  2132\n",
      "(8527, 1066, 1066)\n"
     ]
    }
   ],
   "source": [
    "es_kaq_dataset_xml_filename = \"es_cak_dataset.xml\"\n",
    "\n",
    "# Uniendo ambos datasets\n",
    "df_cak_es = df_history_law.select(\"es\", \"cak\").union(df_new_testament.select(\"es.content\", \"cak.content\"))\n",
    "df_cak_es = df_cak_es.select(clean_text(col(\"es\")).alias(\"es\"),clean_text(col(\"cak\")).alias(\"cak\"))\n",
    "df_cak_es.show()\n",
    "\n",
    "## Barajando datasets\n",
    "shuffled_df = df_cak_es.orderBy(F.rand(seed=2)).distinct()\n",
    "nrows = shuffled_df.count()\n",
    "\n",
    "## Separación en subconjuntos de datos\n",
    "df_train_cak_es = shuffled_df.limit(int(round(0.8*nrows, 0)))\n",
    "df_valid_cak_es = shuffled_df.subtract(df_train_cak_es).limit(int(round(0.1*nrows, 0)))\n",
    "\n",
    "df_test_cak_es = shuffled_df.subtract(df_train_cak_es).subtract(df_valid_cak_es)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cak_es.select(\"*\").write\\\n",
    "    .format(\"com.databricks.spark.xml\")\\\n",
    "    .option(\"rootTag\", \"data\")\\\n",
    "    .option(\"rowTag\", \"sentence\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .save(f\"{file_path}{es_kaq_dataset_xml_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación de archivos de entrada para BPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_es_file = 'final_es_file.txt'\n",
    "df_cak_es.select('es')\\\n",
    "    .repartition(1)\\\n",
    "    .write.format(\"text\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .save(f\"{file_path}{final_es_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cak_file = 'final_cak_file.txt'\n",
    "\n",
    "df_cak_es.select('cak')\\\n",
    "    .repartition(1)\\\n",
    "    .write.format(\"text\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .save(f\"{file_path}{final_cak_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "es_corpus_path = file_path+final_es_file+\"/\" + next(x for x in listdir(f\"{file_path}{final_es_file}\") if x.startswith(\"part\"))\n",
    "cak_corpus_path = file_path+final_cak_file+\"/\" +next(x for x in listdir(f\"{file_path}{final_cak_file}\") if x.startswith(\"part\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Desktop/raw_sentences/final_es_file.txt/part-00000-783c8ed5-c2a3-412f-b70a-064e209c9f19-c000.txt\n",
      "../Desktop/raw_sentences/final_cak_file.txt/part-00000-45a737d6-1c8b-4212-884a-ce4d7dc07f79-c000.txt\n"
     ]
    }
   ],
   "source": [
    "from subword_nmt.learn_bpe import learn_bpe\n",
    "import codecs\n",
    "# Generación de archivo con subpalabras\n",
    "print(es_corpus_path)\n",
    "print(cak_corpus_path)\n",
    "learn_bpe(codecs.open(es_corpus_path, encoding='utf-8'), codecs.open(file_path+\"final_es_file.codes\", 'w', encoding='utf-8'), 1000)\n",
    "learn_bpe(codecs.open(cak_corpus_path, encoding='utf-8'), codecs.open(file_path+\"final_cak_file.codes\", 'w', encoding='utf-8'), 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Desktop/raw_sentences/final_es_file.codes\n",
      "es_corpus path:  ../Desktop/raw_sentences/final_es_file.txt/part-00000-783c8ed5-c2a3-412f-b70a-064e209c9f19-c000.txt\n",
      "#es corpus lines:  10949\n",
      "#cak corpus lines:  10949\n"
     ]
    }
   ],
   "source": [
    "from subword_nmt.apply_bpe import BPE\n",
    "\n",
    "# Codificación de archivos de entrenamiento con subpalabras\n",
    "print(file_path+\"final_es_file.codes\")\n",
    "es_codes_file = codecs.open(file_path+\"final_es_file.codes\", encoding='utf-8')\n",
    "cak_codes_file = codecs.open(file_path+\"final_cak_file.codes\", encoding='utf-8')\n",
    "\n",
    "print(\"es_corpus path: \", es_corpus_path)\n",
    "es_corpus = codecs.open(es_corpus_path, encoding='utf-8')\n",
    "cak_corpus = codecs.open(cak_corpus_path, encoding='utf-8')\n",
    "\n",
    "es_bpe_corpus = codecs.open(file_path+\"es_corpus.bpe\", 'w', encoding='utf-8')\n",
    "cak_bpe_corpus = codecs.open(file_path+\"cak_corpus.bpe\", 'w', encoding='utf-8')\n",
    "\n",
    "es_bpe = BPE(es_codes_file)\n",
    "cak_bpe = BPE(cak_codes_file)\n",
    "\n",
    "n_es_corpus_lines = 0\n",
    "n_cak_corpus_lines = 0\n",
    "\n",
    "for line in es_corpus:\n",
    "    es_bpe_corpus.write(es_bpe.process_line(line, None))\n",
    "    n_es_corpus_lines = n_es_corpus_lines + 1\n",
    "for line in cak_corpus:\n",
    "    cak_bpe_corpus.write(cak_bpe.process_line(line, None))\n",
    "    n_cak_corpus_lines = n_cak_corpus_lines + 1\n",
    "print(\"#es corpus lines: \", n_es_corpus_lines)\n",
    "print(\"#cak corpus lines: \", n_cak_corpus_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inspect import getmembers, isfunction\n",
    "from subword_nmt import apply_bpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalización para generación de archivos de entrada al modelo\n",
    "1. Se genera un archivo con las oraciones crudas\n",
    "2. Se ingresa al modelo de BPE para entrenamiento y generación de vocabularios\n",
    "3. Se pasa cada una de las líneas por el modelo BPE para generar los archivos de entrada al modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def df_preprocessing(df, alias, output_dir):\n",
    "    df_text_dir = f\"{output_dir}{alias}_dir\"\n",
    "    codes_file_path = f\"{output_dir}{alias}.codes\"\n",
    "    bpe_path = f\"{output_dir}{alias}.bpe\"\n",
    "    \n",
    "    print(\"raw text dir: \", df_text_dir)\n",
    "    print(\"codes file: \", codes_file_path)\n",
    "    print(\"bpe file: \", bpe_path)\n",
    "    \n",
    "    print(\"Sample df rows: \")\n",
    "    df.select('*').show()\n",
    "    # Escribir df a archivo\n",
    "    df.select('*')\\\n",
    "        .repartition(1)\\\n",
    "        .write.format('text')\\\n",
    "        .mode('overwrite')\\\n",
    "        .option('header', 'true')\\\n",
    "        .save(df_text_dir)\n",
    "    text_file_path = df_text_dir+\"/\"+next(x for x in listdir(f\"{df_text_dir}\") if x.startswith(\"part\"))\n",
    "    learn_bpe(codecs.open(text_file_path, encoding='utf-8'), codecs.open(codes_file_path, \"w\", encoding='utf-8'), 1000)\n",
    "    \n",
    "    # Codificación de corpus a subpalabras\n",
    "    codes_file = codecs.open(codes_file_path, encoding='utf-8')\n",
    "    corpus_file = codecs.open(text_file_path, encoding='utf-8')\n",
    "    bpe_corpus_file = codecs.open(bpe_path, 'w', encoding='utf-8')\n",
    "    \n",
    "    bpe = BPE(codes_file)\n",
    "    n_lines = 0\n",
    "    for line in corpus_file:\n",
    "        n_lines += 1\n",
    "        bpe_corpus_file.write(bpe.process_line(line, None))\n",
    "    return n_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw text dir:  ../Desktop/raw_sentences/preprocessed/es_train_dir\n",
      "codes file:  ../Desktop/raw_sentences/preprocessed/es_train.codes\n",
      "bpe file:  ../Desktop/raw_sentences/preprocessed/es_train.bpe\n",
      "Sample df rows: \n",
      "+--------------------+\n",
      "|                  es|\n",
      "+--------------------+\n",
      "| efecto de absolver.|\n",
      "|apoyo a la formac...|\n",
      "|ausencia de culpa...|\n",
      "|interés superior ...|\n",
      "|          juramento.|\n",
      "|es la unidad bási...|\n",
      "|se le declara reb...|\n",
      "|quebrantar, viola...|\n",
      "|entre algunas per...|\n",
      "|la información re...|\n",
      "|listado de viajes...|\n",
      "| y les dijo: --es...|\n",
      "| recibidnos. a na...|\n",
      "| porque cada árbo...|\n",
      "| de cierto os dig...|\n",
      "| les dijo jesús: ...|\n",
      "| jesús recorría t...|\n",
      "| por esto el mund...|\n",
      "| asimismo, un bue...|\n",
      "| sucedió que, est...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "raw text dir:  ../Desktop/raw_sentences/preprocessed/cak_train_dir\n",
      "codes file:  ../Desktop/raw_sentences/preprocessed/cak_train.codes\n",
      "bpe file:  ../Desktop/raw_sentences/preprocessed/cak_train.bpe\n",
      "Sample df rows: \n",
      "+--------------------+\n",
      "|                 cak|\n",
      "+--------------------+\n",
      "|rub'anik jun kuyu...|\n",
      "|to'ïk chi tiya' r...|\n",
      "|toq nuq'alajirisa...|\n",
      "|rejqalem kik'asle...|\n",
      "|     qitzij ch'onïk.|\n",
      "|ja re' rub'eyal r...|\n",
      "|nb'ix ch'a'ojinel...|\n",
      "|ruq'ajik tzij, ru...|\n",
      "|chikikojöl ka'i' ...|\n",
      "|rutzijol pa ruwi'...|\n",
      "|rucholajem b'eyaj...|\n",
      "| y xubij cˈa chuk...|\n",
      "| tijakaˈ cˈa ri i...|\n",
      "| ri cheˈ netamex ...|\n",
      "| y can kitzij cˈa...|\n",
      "| y ri jesús xubij...|\n",
      "| ri jesús can ron...|\n",
      "| pero xapon jun k...|\n",
      "| ye qˈuiy cˈa ri ...|\n",
      "| y yacˈa tek ri j...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "raw text dir:  ../Desktop/raw_sentences/preprocessed/es_valid_dir\n",
      "codes file:  ../Desktop/raw_sentences/preprocessed/es_valid.codes\n",
      "bpe file:  ../Desktop/raw_sentences/preprocessed/es_valid.bpe\n",
      "Sample df rows: \n",
      "+--------------------+\n",
      "|                  es|\n",
      "+--------------------+\n",
      "| entonces ellos r...|\n",
      "| fuisteis sepulta...|\n",
      "| entonces se reun...|\n",
      "| mercadería de or...|\n",
      "| decidid, pues, e...|\n",
      "| la ley y los pro...|\n",
      "| algunos comenzar...|\n",
      "| y el que no fue ...|\n",
      "| entonces maría d...|\n",
      "| porque si alguie...|\n",
      "| y ésta es la con...|\n",
      "| y para aclarar a...|\n",
      "| porque conocemos...|\n",
      "| bueno es ser sie...|\n",
      "| de esta manera, ...|\n",
      "| hermanos míos, n...|\n",
      "| no tengo conocim...|\n",
      "| ¿es dios solamen...|\n",
      "| así que, no os a...|\n",
      "| a fin de capacit...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "raw text dir:  ../Desktop/raw_sentences/preprocessed/cak_valid_dir\n",
      "codes file:  ../Desktop/raw_sentences/preprocessed/cak_valid.codes\n",
      "bpe file:  ../Desktop/raw_sentences/preprocessed/cak_valid.bpe\n",
      "Sample df rows: \n",
      "+--------------------+\n",
      "|                 cak|\n",
      "+--------------------+\n",
      "| y ri principaliˈ...|\n",
      "| y chukaˈ tek xix...|\n",
      "| y rumariˈ ri apó...|\n",
      "| y ri nbequicˈayi...|\n",
      "| y can ticˈojeˈ c...|\n",
      "| y tek cˈa ma jan...|\n",
      "| y yecˈo cˈa ri x...|\n",
      "| y can chupan cˈa...|\n",
      "| y tek ri maría r...|\n",
      "| riyix iwetaman c...|\n",
      "| y quinojel cˈa r...|\n",
      "| y ruyaˈon chukaˈ...|\n",
      "| queriˈ nbij chiw...|\n",
      "| yacˈa riyin can ...|\n",
      "| y wi riyix queri...|\n",
      "| wachˈalal, ma ch...|\n",
      "| riyin nunaˈ ri w...|\n",
      "| ri dios, ¿la xax...|\n",
      "| riyix ma nicˈatz...|\n",
      "| xeruyaˈ cˈa re a...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "raw text dir:  ../Desktop/raw_sentences/preprocessed/es_test_dir\n",
      "codes file:  ../Desktop/raw_sentences/preprocessed/es_test.codes\n",
      "bpe file:  ../Desktop/raw_sentences/preprocessed/es_test.bpe\n",
      "Sample df rows: \n",
      "+--------------------+\n",
      "|                  es|\n",
      "+--------------------+\n",
      "|capacidad que tie...|\n",
      "|            permuta.|\n",
      "|         separación.|\n",
      "|persona que mata ...|\n",
      "|cada comunidad ma...|\n",
      "|se han publicado ...|\n",
      "|hoy en día, despu...|\n",
      "|que para armoniza...|\n",
      "|el ejercicio de s...|\n",
      "|        articulo 27.|\n",
      "|sencillez del pro...|\n",
      "| estén ceñidos vu...|\n",
      "| cuando veis que ...|\n",
      "| hermanos, hablo ...|\n",
      "| más bien, cuando...|\n",
      "| cuando pasaban p...|\n",
      "| recogieron, pues...|\n",
      "| y seréis entrega...|\n",
      "| y fue reprendido...|\n",
      "| cuando yo envíe ...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "raw text dir:  ../Desktop/raw_sentences/preprocessed/cak_test_dir\n",
      "codes file:  ../Desktop/raw_sentences/preprocessed/cak_test.codes\n",
      "bpe file:  ../Desktop/raw_sentences/preprocessed/cak_test.bpe\n",
      "Sample df rows: \n",
      "+--------------------+\n",
      "|                 cak|\n",
      "+--------------------+\n",
      "|ri kowil ruchajin...|\n",
      "|k'exonïk / jalwac...|\n",
      "|        jachojri'ïl.|\n",
      "|jun winäq tojon c...|\n",
      "|ri jujun tinamït ...|\n",
      "|xeb'an chupam re ...|\n",
      "|rusamajixik ri ch...|\n",
      "|richin rujunamaxi...|\n",
      "|rokisaxik pwaq ri...|\n",
      "|           mokaj 27.|\n",
      "|  ko'öl rusamajixik.|\n",
      "| tichajij cˈa ri ...|\n",
      "| tek xa can niqui...|\n",
      "| wachˈalal, astap...|\n",
      "| pero tek ri kach...|\n",
      "| y ri tinamit ri ...|\n",
      "| ri discípulos ca...|\n",
      "| y xquixjachalox ...|\n",
      "| y ruma cˈa ri et...|\n",
      "| y riyin xtintek ...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "raw text dir:  ../Desktop/raw_sentences/preprocessed/es_general_dir\n",
      "codes file:  ../Desktop/raw_sentences/preprocessed/es_general.codes\n",
      "bpe file:  ../Desktop/raw_sentences/preprocessed/es_general.bpe\n",
      "Sample df rows: \n",
      "+--------------------+\n",
      "|                  es|\n",
      "+--------------------+\n",
      "|            abogado.|\n",
      "|profesional del d...|\n",
      "|            abortar.|\n",
      "|provocar la muert...|\n",
      "|        absolutorio.|\n",
      "| efecto de absolver.|\n",
      "|           absolver.|\n",
      "|perdón o dar por ...|\n",
      "|         posiciones.|\n",
      "|cuando una de las...|\n",
      "|         abstención.|\n",
      "|    falta de acción.|\n",
      "|           accesión.|\n",
      "|modo de adquirir ...|\n",
      "|acceso a la infor...|\n",
      "|es el derecho de ...|\n",
      "|dicha información...|\n",
      "|             acción.|\n",
      "|derecho de presen...|\n",
      "|       acción penal.|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "raw text dir:  ../Desktop/raw_sentences/preprocessed/cak_general_dir\n",
      "codes file:  ../Desktop/raw_sentences/preprocessed/cak_general.codes\n",
      "bpe file:  ../Desktop/raw_sentences/preprocessed/cak_general.bpe\n",
      "Sample df rows: \n",
      "+--------------------+\n",
      "|                 cak|\n",
      "+--------------------+\n",
      "|solonel mak/to'onel.|\n",
      "|ri etamanel rik'i...|\n",
      "|           tzaqonïk.|\n",
      "|rukamik jun ne'y ...|\n",
      "|majun rumak/kuyun...|\n",
      "|rub'anik jun kuyu...|\n",
      "|          kuyuj mak.|\n",
      "|rukuyik rumak jun...|\n",
      "|         ch'ob'onïk.|\n",
      "|toq jun chi ke ri...|\n",
      "|choj k'ojlem/q'i'...|\n",
      "|majun achike ta x...|\n",
      "|           k'iyirem.|\n",
      "|jun rub'eyal rich...|\n",
      "|  ruk'ulik rutzijol.|\n",
      "|jun ruch'ojib'al ...|\n",
      "|re to'ïk re' rich...|\n",
      "|         ch'ojib'äl.|\n",
      "|ruch'ojib'al jun ...|\n",
      "| ruk'utik ajch'a'oj.|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10949"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Corpus de entrenamiento\n",
    "df_preprocessing(df_train_cak_es.select('es'), 'es_train', '../Desktop/raw_sentences/preprocessed/')\n",
    "df_preprocessing(df_train_cak_es.select('cak'), 'cak_train', '../Desktop/raw_sentences/preprocessed/')\n",
    "# Corpus de validación\n",
    "df_preprocessing(df_valid_cak_es.select('es'), 'es_valid', '../Desktop/raw_sentences/preprocessed/')\n",
    "df_preprocessing(df_valid_cak_es.select('cak'), 'cak_valid', '../Desktop/raw_sentences/preprocessed/')\n",
    "# Corpus de test\n",
    "df_preprocessing(df_test_cak_es.select('es'), 'es_test', '../Desktop/raw_sentences/preprocessed/')\n",
    "df_preprocessing(df_test_cak_es.select('cak'), 'cak_test', '../Desktop/raw_sentences/preprocessed/')\n",
    "\n",
    "# Corpus general\n",
    "df_preprocessing(df_cak_es.select('es'), 'es_general', '../Desktop/raw_sentences/preprocessed/')\n",
    "df_preprocessing(df_cak_es.select('cak'), 'cak_general', '../Desktop/raw_sentences/preprocessed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-07 02:06:03.317203: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-05-07 02:06:04.294752: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-05-07 02:06:04.295480: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-05-07 02:06:04.335349: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-05-07 02:06:04.335409: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (mynorxico): /proc/driver/nvidia/version does not exist\n",
      "2021-05-07 02:06:04.335676: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-05-07 02:06:04.336052: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-05-07 02:06:04.984232: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-05-07 02:06:05.962726: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-05-07 02:06:05.963405: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-05-07 02:06:06.000501: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-05-07 02:06:06.000556: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (mynorxico): /proc/driver/nvidia/version does not exist\n",
      "2021-05-07 02:06:06.000949: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-05-07 02:06:06.001436: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "!onmt-build-vocab --size 50000 --save_vocab ../Desktop/raw_sentences/preprocessed/es_vocab ../Desktop/raw_sentences/preprocessed/es_general.bpe\n",
    "\n",
    "!onmt-build-vocab --size 50000 --save_vocab ../Desktop/raw_sentences/preprocessed/cak_vocab ../Desktop/raw_sentences/preprocessed/cak_general.bpe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
